{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import treelite\n",
    "import tl2cgen\n",
    "import sklearn.datasets as datasets\n",
    "import xgboost as xgb\n",
    "import numpy as np\n",
    "import subprocess\n",
    "import random\n",
    "import subprocess\n",
    "import matplotlib.pyplot as plt\n",
    "import platform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_c_array_string(array):\n",
    "    array_string = \"{\\n\"\n",
    "    array_string += \",\\n\".join(\"{\" + \", \".join(str(x) for x in row) + \"}\" for row in array)\n",
    "    array_string += \"\\n}\"\n",
    "    return array_string\n",
    "\n",
    "def count_decimals(number):\n",
    "    str_num = str(number)\n",
    "    if '.' not in str_num:\n",
    "        return 0\n",
    "    return len(str_num) - str_num.index('.') - 1\n",
    "\n",
    "def beg_c_file_str() :\n",
    "    a = \"\"\"\n",
    "#include <stdio.h>\n",
    "#include <inttypes.h>\n",
    "#include \"sdkconfig.h\"\n",
    "#include \"freertos/FreeRTOS.h\"\n",
    "#include \"freertos/task.h\"\n",
    "#include \"esp_chip_info.h\"\n",
    "#include \"esp_flash.h\"\n",
    "#include \"esp_system.h\"\n",
    "#include \"esp_timer.h\"\n",
    "#include <stdlib.h>\n",
    "#include <string.h>\n",
    "#include <float.h>\n",
    "#include <math.h>\n",
    "#include <stdint.h>\n",
    "\n",
    "union Entry {\n",
    "  int missing;\n",
    "  float fvalue;\n",
    "  int qvalue;\n",
    "};\n",
    "\n",
    "double elapsed_time;\n",
    "int64_t start, end;\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "    return a\n",
    "\n",
    "def makeTimingString(val_nr, nr_results, reuses, treedepth, rootnodes):\n",
    "    a = \"\"\"\n",
    "//////////////////////////////////////////////\n",
    "\n",
    "start = esp_timer_get_time();\n",
    "for (int z = 0; z < \"\"\"+str(reuses)+\"\"\"; z++) {\n",
    "    for (int j = 0; j < sizeof(validation_instances\"\"\"+str(val_nr)+\"\"\")/sizeof(validation_instances\"\"\"+str(val_nr)+\"\"\"[0]); j++) {\n",
    "        float result\"\"\"+str(val_nr)+\"\"\"[\"\"\"+str(nr_results)+\"\"\"]={0.0f};\n",
    "        predictN\"\"\"+str(val_nr)+\"m\"+str(treedepth)+\"td\"+str(rootnodes)+\"rn\"+\"\"\"(validation_instances\"\"\"+str(val_nr)+\"\"\"[j], 0, &result\"\"\"+str(val_nr)+\"\"\");\n",
    "    }\n",
    "}\n",
    "end = esp_timer_get_time();\n",
    "elapsed_time = ((double) (end - start)) / 1000000.0;\n",
    "printf(\"Time elapsed: %f, for N\"\"\"+str(val_nr)+'m'+str(treedepth)+'td'+str(rootnodes)+'rn'+\"\"\" \\\\n\", elapsed_time);\n",
    "\n",
    "start = esp_timer_get_time();\n",
    "for (int z = 0; z < \"\"\"+str(reuses)+\"\"\"; z++) {\n",
    "    for (int j = 0; j < sizeof(validation_instances\"\"\"+str(val_nr)+\"\"\")/sizeof(validation_instances\"\"\"+str(val_nr)+\"\"\"[0]); j++) {\n",
    "        float result\"\"\"+str(val_nr)+\"\"\"[\"\"\"+str(nr_results)+\"\"\"]={0.0f};\n",
    "        predictQ\"\"\"+str(val_nr)+\"m\"+str(treedepth)+\"td\"+str(rootnodes)+\"rn\"+\"\"\"(validation_instances\"\"\"+str(val_nr)+\"\"\"[j], 0, &result\"\"\"+str(val_nr)+\"\"\");\n",
    "    }\n",
    "}\n",
    "end = esp_timer_get_time();\n",
    "elapsed_time = ((double) (end - start)) / 1000000.0;\n",
    "printf(\"Time elapsed: %f, for Q\"\"\"+str(val_nr)+'m'+str(treedepth)+'td'+str(rootnodes)+'rn'+\"\"\" \\\\n\", elapsed_time);\n",
    "\n",
    "\n",
    "start = esp_timer_get_time();\n",
    "for (int z = 0; z < \"\"\"+str(reuses)+\"\"\"; z++) {\n",
    "    for (int j = 0; j < sizeof(validation_instances\"\"\"+str(val_nr)+\"\"\")/sizeof(validation_instances\"\"\"+str(val_nr)+\"\"\"[0]); j++) {\n",
    "        float result\"\"\"+str(val_nr)+\"\"\"[\"\"\"+str(nr_results)+\"\"\"]={0.0f};\n",
    "        predictF\"\"\"+str(val_nr)+\"m\"+str(treedepth)+\"td\"+str(rootnodes)+\"rn\"+\"\"\"(validation_instances\"\"\"+str(val_nr)+\"\"\"[j], 0, &result\"\"\"+str(val_nr)+\"\"\");\n",
    "    }\n",
    "}\n",
    "\n",
    "end = esp_timer_get_time();\n",
    "elapsed_time = ((double) (end - start)) / 1000000.0;\n",
    "printf(\"Time elapsed: %f, for F\"\"\"+str(val_nr)+'m'+str(treedepth)+'td'+str(rootnodes)+'rn'+\"\"\" \\\\n\", elapsed_time);\n",
    "\n",
    "\n",
    "//////////////////////////////////////////////\n",
    "\"\"\"\n",
    "    return a\n",
    "\n",
    "def makeFunctionString(val_nr, treedepth, rootnodes, features):\n",
    "\n",
    "    # Copy predict function from NO PARAM model to function string\n",
    "    a=\"void predictN\"+str(val_nr)+\"m\"+str(treedepth)+\"td\"+str(rootnodes)+\"rn\"+\"(union Entry* data, int pred_margin, float* result) {\\n\"\n",
    "    with open(\"./Trees/model\"+str(val_nr)+\"N\"+str(treedepth)+\"td\"+str(rootnodes)+\"rn\"+\"/main.c\", \"r\") as f:\n",
    "        lines = f.readlines()\n",
    "\n",
    "    start_line = next(i for i, line in enumerate(lines) if 'void predict(union Entry* data, int pred_margin, float* result) {' in line)\n",
    "    end_line = next(i for i, line in enumerate(lines) if 'if (!pred_margin) { postprocess(result);' in line)\n",
    "    content = lines[start_line+1:end_line]\n",
    "    a = a + \"\".join(content) + \"}\\n\\n\"\n",
    "\n",
    "    # Copy predict function from FLINT model to function string\n",
    "    a+=\"void predictF\"+str(val_nr)+\"m\"+str(treedepth)+\"td\"+str(rootnodes)+\"rn\"+\"(union Entry* data, int pred_margin, float* result) {\\n\"\n",
    "    with open(\"./Trees/model\"+str(val_nr)+\"F\"+str(treedepth)+\"td\"+str(rootnodes)+\"rn\"+\"/main.c\", \"r\") as f:\n",
    "        lines = f.readlines()\n",
    "\n",
    "    start_line = next(i for i, line in enumerate(lines) if 'void predict(union Entry* data, int pred_margin, float* result) {' in line)\n",
    "    end_line = next(i for i, line in enumerate(lines) if 'if (!pred_margin) { postprocess(result);' in line)\n",
    "    content = lines[start_line+1:end_line]\n",
    "    a = a + \"\".join(content) + \"}\\n\\n\"\n",
    "\n",
    "    # Copy predict function from QUANTIZE model to function string, with the quantize function declared first\n",
    "    a = a + \"\".join(content) + \"}\\n\\nint quantize\"+str(val_nr)+\"m\"+str(treedepth)+\"td\"+str(rootnodes)+\"rn\"+\"(float val, unsigned fid) {\\n\"\n",
    "    with open(\"./Trees/model\"+str(val_nr)+\"Q\"+str(treedepth)+\"td\"+str(rootnodes)+\"rn\"+\"/quantize.c\", \"r\") as f:\n",
    "        lines = f.readlines()\n",
    "    start_line = next(i for i, line in enumerate(lines) if 'int quantize(float val, unsigned fid) {' in line)\n",
    "    a = a + \"\".join(lines[2:start_line-6])+\"\\n\"\n",
    "    content = lines[start_line+1:]\n",
    "    a = a + \"\".join(content) + \"\\n\"\n",
    "  \n",
    "    \n",
    "    a+=\"void predictQ\"+str(val_nr)+\"m\"+str(treedepth)+\"td\"+str(rootnodes)+\"rn\"+\"(union Entry* data, int pred_margin, float* result) {\\n\"\n",
    "    with open(\"./Trees/model\"+str(val_nr)+\"Q\"+str(treedepth)+\"td\"+str(rootnodes)+\"rn\"+\"/main.c\", \"r\") as f:\n",
    "        lines = f.readlines()\n",
    "\n",
    "    start_line = next(i for i, line in enumerate(lines) if 'void predict(union Entry* data, int pred_margin, float* result) {' in line)\n",
    "    end_line = next(i for i, line in enumerate(lines) if 'if (!pred_margin) { postprocess(result);' in line)\n",
    "    lines[start_line+2] = \"const unsigned char is_categorical[] = {\"+''.join(['0, ' for i in range(features)]) + '};\\n'\n",
    "    lines[start_line+5] = \"      data[i].qvalue = quantize\"+str(val_nr)+\"m\"+str(treedepth)+\"td\"+str(rootnodes)+\"rn\"+\"(data[i].fvalue, i);\"\n",
    "    content = lines[start_line+1:end_line]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    return a\n",
    "\n",
    "nr_instances_validation = 10\n",
    "toy_datasets = [datasets.load_iris]\n",
    "tree_depths = [3]\n",
    "nr_root_nodes = 5\n",
    "\n",
    "header_file_str = r'const char *dll_paths[] = {'\n",
    "c_file_str = beg_c_file_str()\n",
    "timing_str = r''\n",
    "functions_str = r''\n",
    "nr_features = []\n",
    "validation_instances = []\n",
    "validation_instances_str = r''\n",
    "nr_validation_reuses = 300\n",
    "\n",
    "for i, dataset in enumerate(toy_datasets):\n",
    "    for depth in tree_depths:\n",
    "\n",
    "        # Train models\n",
    "        X, y = dataset(return_X_y=True)\n",
    "        dtrain = xgb.DMatrix(X, label=y)\n",
    "        params = {\"max_depth\": depth, \"eta\": 0.1, \"objective\": \"multi:softprob\", \"eval_metric\": \"mlogloss\", \"num_class\": 3}\n",
    "        bst = xgb.train(params, dtrain, num_boost_round=nr_root_nodes, evals=[(dtrain, 'train')])\n",
    "        model = treelite.Model.from_xgboost(bst)\n",
    "\n",
    "        path_no_param = \"./Trees/model\"+str(i)+\"N\"+str(depth)+\"td\"+str(nr_root_nodes)+\"rn\"\n",
    "        path_flint = \"./Trees/model\"+str(i)+\"F\"+str(depth)+\"td\"+str(nr_root_nodes)+\"rn\"\n",
    "        path_quantize = \"./Trees/model\"+str(i)+\"Q\"+str(depth)+\"td\"+str(nr_root_nodes)+\"rn\"\n",
    "\n",
    "        # Generate model C code\n",
    "        tl2cgen.generate_c_code(model, dirpath=path_no_param, params={})\n",
    "        tl2cgen.generate_c_code(model, dirpath=path_flint, params={\"flint\" : 1})\n",
    "        tl2cgen.generate_c_code(model, dirpath=path_quantize, params={\"quantize\": 1})\n",
    "\n",
    "        # Generate timing C code per predict function\n",
    "        timing_str += makeTimingString(i, len(np.unique(y)), nr_validation_reuses, depth, nr_root_nodes)\n",
    "        functions_str += makeFunctionString(i, depth, nr_root_nodes, X.shape[1])\n",
    "\n",
    "\n",
    "\n",
    "    # Generate random validation instances with decimal precision equal to the maximum decimal precision of the training data\n",
    "    min_values_feature = []\n",
    "    max_values_feature = []\n",
    "    nr_decimals = np.zeros((X.shape[0], X.shape[1]))\n",
    "    max_decimals = []\n",
    "\n",
    "    nr_features.append(X.shape[1])\n",
    "    for k in range(X.shape[0]):\n",
    "        for j in range(X.shape[1]):\n",
    "            nr_decimals[i][j] = count_decimals(X[k][j])\n",
    "\n",
    "    for k in range(X.shape[1]):\n",
    "        max_decimals.append(max(nr_decimals[:, k]))\n",
    "\n",
    "    for k in range(X.shape[1]):\n",
    "        min_values_feature.append(X[:, k].min())\n",
    "        max_values_feature.append(X[:, k].max())\n",
    "\n",
    "    validation_instances = np.zeros((nr_instances_validation, X.shape[1]))\n",
    "    for j in range(nr_instances_validation):\n",
    "        for k in range(X.shape[1]):\n",
    "            validation_instances[j][k] = round(random.uniform(min_values_feature[k], max_values_feature[k]), int(max_decimals[k]))\n",
    "    \n",
    "    validation_instances_str += 'float validation_instances'+str(i)+'[][' + str(X.shape[1]) + '] = ' + create_c_array_string(validation_instances) + ';\\n'\n",
    "\n",
    "\n",
    "c_file_str += functions_str\n",
    "c_file_str += \"void app_main(void)\\n{\\n\"\n",
    "c_file_str += validation_instances_str\n",
    "c_file_str += timing_str\n",
    "c_file_str += \"\\n}\"\n",
    "with open('generated_speedTestS3.c', 'w') as f:\n",
    "    f.write(c_file_str)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Figure scaling so that 6 bar groups are 10 wide\n",
    "plt.figure(figsize=((len(times)/3)*(10/6), 5))\n",
    "\n",
    "x = np.arange(0, len(times), 3)\n",
    "\n",
    "# Width of a bar \n",
    "width = 2\n",
    "\n",
    "# Create the bar chart for each group with different colors\n",
    "colors = ['red', 'green', 'blue']\n",
    "labels = ['No parameters', 'Flint', 'Quantize']\n",
    "for i in range(3):\n",
    "    plt.bar(x + i*(width/3), times[i::3], color=colors[i], width=width/3, label=labels[i])\n",
    "\n",
    "# Assuming 'names' is your array of group names\n",
    "dataset_names = [func.__name__.replace('datasets.', '') for func in toy_datasets]\n",
    "dataset_names = [f\"{name}{depth}\" for name in dataset_names for depth in tree_depths]\n",
    "\n",
    "for i in range(len(dataset_names)):\n",
    "    dataset_names[i] = dataset_names[i].replace('load_', '')\n",
    "\n",
    "architecture = platform.architecture()\n",
    "\n",
    "# Set the x-tick labels to the group names and remove the x-axis\n",
    "plt.xticks(x-0.5 + width/2, dataset_names)\n",
    "plt.tick_params(axis='x', length=0)\n",
    "\n",
    "plt.ylabel('Seconds')\n",
    "plt.title('Inference times')\n",
    "plt.text(0, -0.1, 'Validation instances per set: '+str(nr_instances_validation)+'\\nValidation set reuses: '+str(nr_validation_reuses)+'\\nNumber of root nodes: '+str(nr_root_nodes)+'\\nSystem info: '+str(architecture), ha='left', va='top', transform=plt.gca().transAxes)\n",
    "\n",
    "# Display the legend\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = ['Quantization', 'Inference']\n",
    "cols=int(len(qtimes)/3)\n",
    "fig, axs = plt.subplots(1, cols, figsize=(cols*2.2, 4))\n",
    "\n",
    "\n",
    "\n",
    "# Assuming 'names' is your array of group names\n",
    "dataset_names = [func.__name__.replace('datasets.', '') for func in toy_datasets]\n",
    "dataset_names = [f\"{name}{depth}\" for name in dataset_names for depth in tree_depths]\n",
    "\n",
    "for i in range(len(dataset_names)):\n",
    "    dataset_names[i] = dataset_names[i].replace('load_', '')\n",
    "\n",
    "architecture = platform.architecture()\n",
    "\n",
    "\n",
    "\n",
    "for i in range(cols):\n",
    "    cft = round(qtimes[3*i]/times[3*i+2]*100)\n",
    "    axs[i].pie([qtimes[3*i+1],qtimes[3*i+2]], autopct='%1.1f%%', startangle=90)\n",
    "    axs[i].axis('equal')  # Equal aspect ratio ensures that pie is drawn as a circle.\n",
    "    axs[i].text(0.5, 0.1, dataset_names[i], size=12, ha=\"center\", transform=axs[i].transAxes)\n",
    "    axs[i].text(0.5, 0.05, \"CFT = \"+str(cft)+\"%\", size=10, ha=\"center\", transform=axs[i].transAxes)\n",
    "# Add a legend\n",
    "plt.legend(labels, loc=\"best\")\n",
    "fig.suptitle('Quantization time breakdown', weight='bold', size='large', y=0.98, x=0.3)\n",
    "fig.text(0.145, 0.92, 'Validation instances per set: '+str(nr_instances_validation)+'\\nValidation set reuses: '+str(nr_validation_reuses)+'\\nNumber of root nodes: '+str(nr_root_nodes)+'\\nSystem info: '+str(architecture)+'\\nCTF = Compared to Full Time', size=9, ha='left', va='top')\n",
    "\n",
    "\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_names = [func.__name__.replace('datasets.', '') for func in toy_datasets]\n",
    "for i in range(len(dataset_names)):\n",
    "    dataset_names[i] = dataset_names[i].replace('load_', '')\n",
    "\n",
    "\n",
    "times_no_parameters = [np.mean(times[i*3::len(tree_depths)*3]) for i in range(len(tree_depths))]\n",
    "times_flint = [np.mean(times[i*3+1::len(tree_depths)*3]) for i in range(len(tree_depths))]\n",
    "times_quantize = [np.mean(times[i*3+2::len(tree_depths)*3]) for i in range(len(tree_depths))]\n",
    "\n",
    "architecture = platform.architecture()\n",
    "# Create the line plot for each group with different colors\n",
    "plt.plot(range(len(tree_depths)), times_no_parameters, color='red', marker='*', label='No parameters')\n",
    "plt.plot(range(len(tree_depths)), times_flint, color='green', marker='^', label='Flint')\n",
    "plt.plot(range(len(tree_depths)), times_quantize, color='blue', marker='s', label='Quantize')\n",
    "\n",
    "# Set the x-tick labels to the values in tree_depths\n",
    "plt.xticks(range(len(tree_depths)), tree_depths)\n",
    "\n",
    "plt.xlabel('Maximum tree depth')\n",
    "plt.ylabel('Time [s]')\n",
    "plt.title('Average inference time per tree depth')\n",
    "\n",
    "plt.text(0, -0.15, 'Datasets used: '+str(dataset_names)+'.\\nValidation instances per set: '+str(nr_instances_validation)+'\\nValidation set reuses: '+str(nr_validation_reuses)+'\\nSystem info: '+str(architecture), ha='left', va='top', transform=plt.gca().transAxes)\n",
    "\n",
    "# Display the legend\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5",
   "metadata": {},
   "outputs": [],
   "source": [
    "times_per_nr_features= []\n",
    "\n",
    "indices = sorted(range(len(nr_features)), key=nr_features.__getitem__)\n",
    "sorted_nr_features = sorted(nr_features)\n",
    "\n",
    "dataset_names = [func.__name__.replace('datasets.', '') for func in toy_datasets]\n",
    "for i in range(len(dataset_names)):\n",
    "    dataset_names[i] = dataset_names[i].replace('load_', '')\n",
    "\n",
    "times_no_parameters = [[np.mean(times[i*len(tree_depths)*3:i*len(tree_depths)*3+len(tree_depths)*3:3]) for i in range(len(tree_depths))][j] for j in indices]\n",
    "times_flint = [[np.mean(times[i*len(tree_depths)*3+1:i*len(tree_depths)*3+len(tree_depths)*3+1:3]) for i in range(len(tree_depths))][j] for j in indices]\n",
    "times_quantize = [[np.mean(times[i*len(tree_depths)*3+2:i*len(tree_depths)*3+len(tree_depths)*3+2:3]) for i in range(len(tree_depths))][j] for j in indices]\n",
    "\n",
    "\n",
    "\n",
    "# Create the line plot for each group with different colors\n",
    "plt.plot(range(len(sorted_nr_features)), times_no_parameters, color='red', marker='*', label='No parameters')\n",
    "plt.plot(range(len(sorted_nr_features)), times_flint, color='green', marker='^', label='Flint')\n",
    "plt.plot(range(len(sorted_nr_features)), times_quantize, color='blue', marker='s', label='Quantize')\n",
    "\n",
    "# Set the x-tick labels to the values in tree_depths\n",
    "plt.xticks(range(len(sorted_nr_features)), sorted_nr_features)\n",
    "\n",
    "plt.xlabel('Number of features')\n",
    "plt.ylabel('Time [s]')\n",
    "plt.title('Average inference time per number of features')\n",
    "\n",
    "plt.text(0, -0.15, 'Datasets used: '+str(dataset_names)+'.\\nValidation instances per set: '+str(nr_instances_validation)+'\\nValidation set reuses: '+str(nr_validation_reuses)+'\\nSystem info: '+str(architecture), ha='left', va='top', transform=plt.gca().transAxes)\n",
    "\n",
    "# Display the legend\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
