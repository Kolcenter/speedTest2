{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import treelite\n",
    "import tl2cgen\n",
    "import sklearn.datasets as datasets\n",
    "import xgboost as xgb\n",
    "import numpy as np\n",
    "import subprocess\n",
    "import random\n",
    "import subprocess\n",
    "import matplotlib.pyplot as plt\n",
    "import platform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def FreeTayK(path: str):\n",
    "    with open(path, 'r+') as f:\n",
    "        data = f.readlines()\n",
    "        f.seek(0, 0)\n",
    "        f.write('#include \"quantize.c\"\\n' + ''.join(data[2:]))\n",
    "\n",
    "def FreeBlueface(path: str):\n",
    "    with open(path+\"/main.c\", 'r+') as f:\n",
    "        data = f.readlines()\n",
    "        del data[25:32]\n",
    "        f.seek(0, 0)\n",
    "        f.write(''.join(data))\n",
    "        f.truncate()  # Truncate the file to the current position\n",
    "\n",
    "    with open(path+\"/header.h\", 'r+') as f:\n",
    "        dataQ = f.readlines()\n",
    "        f.seek(0, 0)\n",
    "        dataQ.append('__declspec(dllexport) int quantize(float val, unsigned fid);\\n')\n",
    "        f.write(''.join(dataQ))\n",
    "\n",
    "\n",
    "def create_c_array_string(array):\n",
    "    array_string = \"{\\n\"\n",
    "    array_string += \",\\n\".join(\"{\" + \", \".join(str(x) for x in row) + \"}\" for row in array)\n",
    "    array_string += \"\\n}\"\n",
    "    return array_string\n",
    "\n",
    "def count_decimals(number):\n",
    "    str_num = str(number)\n",
    "    if '.' not in str_num:\n",
    "        return 0\n",
    "    return len(str_num) - str_num.index('.') - 1\n",
    "\n",
    "def beg_c_file_str(nr_datasets, nr_treedepths) :\n",
    "    a = \"\"\"\n",
    "#include <time.h>\n",
    "#include <stdio.h>\n",
    "#include <stdlib.h>\n",
    "#include <string.h>\n",
    "#include <windows.h>\n",
    "#include \"dll_paths.h\"\n",
    "\n",
    "\n",
    "typedef void (*PredictFunction)(union Entry*, int, float*);\n",
    "typedef int (*QuantizeFunction)(float, unsigned);\n",
    "int main() {\n",
    "char times[\"\"\"+str(nr_datasets*nr_treedepths*30)+\"\"\"] = \"\";\n",
    "char qtimes[\"\"\"+str(nr_datasets*nr_treedepths*30)+\"\"\"] = \"\";\n",
    "int k=0;\n",
    "int nr_treedepths = \"\"\"+str(nr_treedepths)+\"\"\";\n",
    "    \"\"\"\n",
    "    return a\n",
    "\n",
    "def mid_c_file_str(i, nr_results, reuses, nr_features):\n",
    "    a = \"\"\"\n",
    "//////////////////////////////////////////////\n",
    "\n",
    "    for (int i = (0+(k*3))*nr_treedepths; i < (3 +(k*3))*nr_treedepths; i++) {\n",
    "\n",
    "        HINSTANCE hDLL = LoadLibraryA(dll_paths[i]);\n",
    "        if (hDLL == NULL) {\n",
    "            return 1;\n",
    "        }\n",
    "        PredictFunction predict = (PredictFunction) GetProcAddress(hDLL, \"predict\");\n",
    "        clock_t start = clock();\n",
    "        for (int z = 0; z < \"\"\"+str(reuses)+\"\"\"; z++) {\n",
    "            for (int j = 0; j < sizeof(validation_instances\"\"\"+str(i)+\"\"\")/sizeof(validation_instances\"\"\"+str(i)+\"\"\"[0]); j++) {\n",
    "                float result[\"\"\"+str(nr_results)+\"\"\"]={0.0f};\n",
    "                predict(validation_instances\"\"\"+str(i)+\"\"\"[j], 0, &result);\n",
    "            }\n",
    "        }\n",
    "        FreeLibrary(hDLL);\n",
    "        clock_t end = clock();\n",
    "        double elapsed_time = ((double) (end - start)) / CLOCKS_PER_SEC;\n",
    "        sprintf(times + strlen(times), \"%6.3f\\\\n\", elapsed_time);\n",
    "\n",
    "\n",
    "        if ((i+1) % 3 == 0) {\n",
    "            HINSTANCE hDLL = LoadLibraryA(qbr_dll_paths[(((i+1)/3)-1)]);\n",
    "            if (hDLL == NULL) {\n",
    "                return 1;\n",
    "            }\n",
    "            PredictFunction predict = (PredictFunction) GetProcAddress(hDLL, \"predict\");\n",
    "            QuantizeFunction quantize = (QuantizeFunction) GetProcAddress(hDLL, \"quantize\");\n",
    "            clock_t start = clock();\n",
    "            for (int z = 0; z < \"\"\"+str(reuses)+\"\"\"; z++) {\n",
    "                for (int j = 0; j < sizeof(validation_instances\"\"\"+str(i)+\"\"\")/sizeof(validation_instances\"\"\"+str(i)+\"\"\"[0]); j++) {\n",
    "                    for (int v = 0; v < \"\"\"+str(nr_features)+\"\"\"; ++v) {\n",
    "                    \n",
    "                        // NOTE: the original line \n",
    "                        // validaton_instances[j][v].missing != -1\n",
    "                        //          is replaced with\n",
    "                        // validaton_instances[j][v] = validaton_instances[i][j]\n",
    "                        // in order to avoid having to give a value to missing but still takes a similar amount of time to execute\n",
    "\n",
    "                        if (!is_categorical[v]) {\n",
    "                        validation_qinstances\"\"\"+str(i)+\"\"\"[j][v] = quantize(validation_instances\"\"\"+str(i)+\"\"\"[j][v], v);\n",
    "                        }\n",
    "                    }\n",
    "                }\n",
    "            }\n",
    "            clock_t half = clock();\n",
    "            for (int z = 0; z < \"\"\"+str(reuses)+\"\"\"; z++) {\n",
    "                for (int j = 0; j < sizeof(validation_instances\"\"\"+str(i)+\"\"\")/sizeof(validation_instances\"\"\"+str(i)+\"\"\"[0]); j++) {\n",
    "                    float result[\"\"\"+str(nr_results)+\"\"\"]={0.0f};\n",
    "                    predict(validation_qinstances\"\"\"+str(i)+\"\"\"[j], 0, &result);\n",
    "                    \n",
    "                }\n",
    "            }\n",
    "\n",
    "            FreeLibrary(hDLL);\n",
    "            clock_t end = clock();\n",
    "            double full_time = ((double) (end - start)) / CLOCKS_PER_SEC;\n",
    "            double half_time1 = ((double) (half - start)) / CLOCKS_PER_SEC;\n",
    "            double half_time2 = ((double) (end - half)) / CLOCKS_PER_SEC;\n",
    "            sprintf(qtimes + strlen(qtimes), \"%6.3f\\\\n%6.3f\\\\n%6.3f\\\\n\", full_time, half_time1, half_time2);\n",
    "        }\n",
    "        \n",
    "    }\n",
    "\n",
    "\n",
    "k++;\n",
    "\n",
    "//////////////////////////////////////////////\n",
    "\"\"\"\n",
    "    return a\n",
    "\n",
    "def end_c_file_str() :\n",
    "    a = \"\"\"\n",
    "FILE *file = fopen(\"times.txt\", \"w\");\n",
    "if (file == NULL) {\n",
    "    printf(\"Could not open file for writing.\\\\n\");\n",
    "    return 1;\n",
    "}\n",
    "fprintf(file, times);\n",
    "fclose(file);\n",
    "\n",
    "FILE *file2 = fopen(\"qtimes.txt\", \"w\");\n",
    "if (file2 == NULL) {\n",
    "    printf(\"Could not open qfile for writing.\\\\n\");\n",
    "    return 1;\n",
    "}\n",
    "fprintf(file2, qtimes);\n",
    "fclose(file2);\n",
    "\n",
    "\n",
    "return 0;\n",
    "}\n",
    "    \"\"\"\n",
    "    return a\n",
    "\n",
    "def createIsCategoricalString(nr_features):\n",
    "    a = 'const unsigned char is_categorical[] = { '\n",
    "    a += ''.join(['0, ' for i in range(nr_features)]) + '};\\n'\n",
    "    return a\n",
    "\n",
    "\n",
    "def compile_c_file(c_file_path):\n",
    "    # gcc is the compiler, -o is used to specify the output file\n",
    "    # 'output' is the name of the output file\n",
    "    command = ['gcc', c_file_path, '-o', 'output']\n",
    "\n",
    "    try:\n",
    "        # Run the command\n",
    "        subprocess.check_call(command)\n",
    "        print(\"Compilation successful.\")\n",
    "    except subprocess.CalledProcessError:\n",
    "        print(\"Compilation failed.\")\n",
    "\n",
    "def run_exe_file(exe_file_path):\n",
    "    try:\n",
    "        # Run the executable file\n",
    "        subprocess.check_call(exe_file_path)\n",
    "        print(\"Execution successful.\")\n",
    "    except subprocess.CalledProcessError:\n",
    "        print(\"Execution failed.\")\n",
    "\n",
    "\n",
    "nr_instances_validation = 1000\n",
    "toy_datasets = [datasets.load_iris, datasets.load_wine, datasets.load_breast_cancer]\n",
    "tree_depths = [1, 3, 5]\n",
    "nr_root_nodes = 20\n",
    "\n",
    "header_file_str = r'const char *dll_paths[] = {'\n",
    "c_file_str = beg_c_file_str(len(toy_datasets), len(tree_depths))\n",
    "dll_file_paths = []\n",
    "qbr_dll_file_paths = []\n",
    "nr_results = []\n",
    "nr_features = []\n",
    "validation_instances = []\n",
    "validation_instances_str = r''\n",
    "nr_validation_reuses = 3000\n",
    "\n",
    "for i, dataset in enumerate(toy_datasets):\n",
    "    for depth in tree_depths:\n",
    "\n",
    "        # Train models\n",
    "        X, y = dataset(return_X_y=True)\n",
    "        dtrain = xgb.DMatrix(X, label=y)\n",
    "        params = {\"max_depth\": depth, \"eta\": 0.1, \"objective\": \"multi:softprob\", \"eval_metric\": \"mlogloss\", \"num_class\": 3}\n",
    "        bst = xgb.train(params, dtrain, num_boost_round=nr_root_nodes, evals=[(dtrain, 'train')])\n",
    "        model = treelite.Model.from_xgboost(bst)\n",
    "\n",
    "        path_no_param = \"./Trees/model\"+str(i)+\"N\"+str(depth)\n",
    "        path_flint = \"./Trees/model\"+str(i)+\"F\"+str(depth)\n",
    "        path_quantize = \"./Trees/model\"+str(i)+\"Q\"+str(depth)\n",
    "\n",
    "        tl2cgen.generate_c_code(model, dirpath=path_no_param, params={})\n",
    "        tl2cgen.generate_c_code(model, dirpath=path_flint, params={\"flint\" : 1})\n",
    "        tl2cgen.generate_c_code(model, dirpath=path_quantize, params={\"quantize\": 1})\n",
    "\n",
    "        # Generate DLLs\n",
    "        path_no_param_dll = path_no_param + '/predict.dll'\n",
    "        path_flint_dll = path_flint + '/predict.dll'\n",
    "        path_quantize_dll = path_quantize + '/predict.dll'\n",
    "        path_qBreakdown_dll = path_quantize + '/qBreakdown.dll'\n",
    "\n",
    "        dll_file_paths.append(path_no_param_dll)\n",
    "        dll_file_paths.append(path_flint_dll)\n",
    "        dll_file_paths.append(path_quantize_dll)\n",
    "        qbr_dll_file_paths.append(path_qBreakdown_dll)\n",
    "\n",
    "        FreeTayK(path_quantize + '/main.c')\n",
    "        \n",
    "        # Compile the generated C code into DLLs\n",
    "        subprocess.run(['gcc', '-shared', '-o', path_no_param_dll, path_no_param + '/main.c']),\n",
    "        subprocess.run(['gcc', '-shared', '-o', path_flint_dll, path_flint + '/main.c']),\n",
    "        subprocess.run(['gcc', '-shared', '-o', path_quantize_dll, path_quantize + '/main.c'])\n",
    "\n",
    "        FreeBlueface(path_quantize)\n",
    "        subprocess.run(['gcc', '-shared', '-o', path_qBreakdown_dll, path_quantize + '/main.c'])\n",
    "\n",
    "\n",
    "\n",
    "    # Generate random validation instances with decimal precision equal to the maximum decimal precision of the training data\n",
    "    min_values_feature = []\n",
    "    max_values_feature = []\n",
    "    nr_decimals = np.zeros((X.shape[0], X.shape[1]))\n",
    "    max_decimals = []\n",
    "\n",
    "    nr_results = len(np.unique(y))\n",
    "    nr_features.append(X.shape[1])\n",
    "    for k in range(X.shape[0]):\n",
    "        for j in range(X.shape[1]):\n",
    "            nr_decimals[i][j] = count_decimals(X[k][j])\n",
    "\n",
    "    for k in range(X.shape[1]):\n",
    "        max_decimals.append(max(nr_decimals[:, k]))\n",
    "\n",
    "\n",
    "    for k in range(X.shape[1]):\n",
    "        min_values_feature.append(X[:, k].min())\n",
    "        max_values_feature.append(X[:, k].max())\n",
    "\n",
    "    validation_instances = np.zeros((nr_instances_validation, X.shape[1]))\n",
    "    for j in range(nr_instances_validation):\n",
    "        for k in range(X.shape[1]):\n",
    "            validation_instances[j][k] = round(random.uniform(min_values_feature[k], max_values_feature[k]), int(max_decimals[k]))\n",
    "    \n",
    "\n",
    "\n",
    "    c_file_str += mid_c_file_str(i, nr_results, nr_validation_reuses, X.shape[1])\n",
    "    validation_instances_str += 'int validation_qinstances'+str(i)+'['+str(nr_instances_validation)+'][' + str(X.shape[1]) + '];\\n'\n",
    "    validation_instances_str += 'float validation_instances'+str(i)+'[][' + str(X.shape[1]) + '] = ' + create_c_array_string(validation_instances) + ';\\n'\n",
    "\n",
    "header_file_str += ', '.join([f'\"{path}\"' for path in dll_file_paths]) + '};\\n'\n",
    "header_file_str += \"const char *qbr_dll_paths[] = {\"\n",
    "header_file_str += ', '.join([f'\"{path}\"' for path in qbr_dll_file_paths]) + '};\\n'\n",
    "header_file_str += createIsCategoricalString(max(nr_features))\n",
    "header_file_str += validation_instances_str\n",
    "\n",
    "\n",
    "\n",
    "with open('dll_paths.h', 'w') as f:\n",
    "    f.write(header_file_str)\n",
    "\n",
    "\n",
    "c_file_str += end_c_file_str()\n",
    "with open('generated_speedTest.c', 'w') as f:\n",
    "    f.write(c_file_str)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2",
   "metadata": {},
   "outputs": [],
   "source": [
    "compile_c_file('generated_speedTest.c')\n",
    "run_exe_file('output')\n",
    "with open('times.txt', 'r') as f:\n",
    "    times_content = f.read()\n",
    "times = np.fromstring(times_content, sep='\\n')\n",
    "print(times)\n",
    "\n",
    "with open('qtimes.txt', 'r') as f:\n",
    "    qtimes_content = f.read()\n",
    "qtimes = np.fromstring(qtimes_content, sep='\\n')\n",
    "print(qtimes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read out times.txt without compiling and running the C code again\n",
    "with open('times.txt', 'r') as f:\n",
    "    times_content = f.read()\n",
    "times = np.fromstring(times_content, sep='\\n')\n",
    "print(times)\n",
    "\n",
    "with open('qtimes.txt', 'r') as f:\n",
    "    qtimes_content = f.read()\n",
    "qtimes = np.fromstring(qtimes_content, sep='\\n')\n",
    "print(qtimes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Figure scaling so that 6 bar groups are 10 wide\n",
    "plt.figure(figsize=((len(times)/3)*(10/6), 5))\n",
    "\n",
    "x = np.arange(0, len(times), 3)\n",
    "\n",
    "# Width of a bar \n",
    "width = 2\n",
    "\n",
    "# Create the bar chart for each group with different colors\n",
    "colors = ['red', 'green', 'blue']\n",
    "labels = ['No parameters', 'Flint', 'Quantize']\n",
    "for i in range(3):\n",
    "    plt.bar(x + i*(width/3), times[i::3], color=colors[i], width=width/3, label=labels[i])\n",
    "\n",
    "# Assuming 'names' is your array of group names\n",
    "dataset_names = [func.__name__.replace('datasets.', '') for func in toy_datasets]\n",
    "dataset_names = [f\"{name}{depth}\" for name in dataset_names for depth in tree_depths]\n",
    "\n",
    "for i in range(len(dataset_names)):\n",
    "    dataset_names[i] = dataset_names[i].replace('load_', '')\n",
    "\n",
    "architecture = platform.architecture()\n",
    "\n",
    "# Set the x-tick labels to the group names and remove the x-axis\n",
    "plt.xticks(x-0.5 + width/2, dataset_names)\n",
    "plt.tick_params(axis='x', length=0)\n",
    "\n",
    "plt.ylabel('Seconds')\n",
    "plt.title('Inference times')\n",
    "plt.text(0, -0.1, 'Validation instances per set: '+str(nr_instances_validation)+'\\nValidation set reuses: '+str(nr_validation_reuses)+'\\nNumber of root nodes: '+str(nr_root_nodes)+'\\nSystem info: '+str(architecture), ha='left', va='top', transform=plt.gca().transAxes)\n",
    "\n",
    "# Display the legend\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = ['Quantization', 'Inference']\n",
    "cols=int(len(qtimes)/3)\n",
    "fig, axs = plt.subplots(1, cols, figsize=(cols*2.2, 4))\n",
    "\n",
    "\n",
    "\n",
    "# Assuming 'names' is your array of group names\n",
    "dataset_names = [func.__name__.replace('datasets.', '') for func in toy_datasets]\n",
    "dataset_names = [f\"{name}{depth}\" for name in dataset_names for depth in tree_depths]\n",
    "\n",
    "for i in range(len(dataset_names)):\n",
    "    dataset_names[i] = dataset_names[i].replace('load_', '')\n",
    "\n",
    "architecture = platform.architecture()\n",
    "\n",
    "\n",
    "\n",
    "for i in range(cols):\n",
    "    cft = round(qtimes[3*i]/times[3*i+2]*100)\n",
    "    axs[i].pie([qtimes[3*i+1],qtimes[3*i+2]], autopct='%1.1f%%', startangle=90)\n",
    "    axs[i].axis('equal')  # Equal aspect ratio ensures that pie is drawn as a circle.\n",
    "    axs[i].text(0.5, 0.1, dataset_names[i], size=12, ha=\"center\", transform=axs[i].transAxes)\n",
    "    axs[i].text(0.5, 0.05, \"CFT = \"+str(cft)+\"%\", size=10, ha=\"center\", transform=axs[i].transAxes)\n",
    "# Add a legend\n",
    "plt.legend(labels, loc=\"best\")\n",
    "fig.suptitle('Quantization time breakdown', weight='bold', size='large', y=0.98, x=0.3)\n",
    "fig.text(0.145, 0.92, 'Validation instances per set: '+str(nr_instances_validation)+'\\nValidation set reuses: '+str(nr_validation_reuses)+'\\nNumber of root nodes: '+str(nr_root_nodes)+'\\nSystem info: '+str(architecture)+'\\nCTF = Compared to Full Time', size=9, ha='left', va='top')\n",
    "\n",
    "\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_names = [func.__name__.replace('datasets.', '') for func in toy_datasets]\n",
    "for i in range(len(dataset_names)):\n",
    "    dataset_names[i] = dataset_names[i].replace('load_', '')\n",
    "\n",
    "\n",
    "times_no_parameters = [np.mean(times[i*3::len(tree_depths)*3]) for i in range(len(tree_depths))]\n",
    "times_flint = [np.mean(times[i*3+1::len(tree_depths)*3]) for i in range(len(tree_depths))]\n",
    "times_quantize = [np.mean(times[i*3+2::len(tree_depths)*3]) for i in range(len(tree_depths))]\n",
    "\n",
    "architecture = platform.architecture()\n",
    "# Create the line plot for each group with different colors\n",
    "plt.plot(range(len(tree_depths)), times_no_parameters, color='red', marker='*', label='No parameters')\n",
    "plt.plot(range(len(tree_depths)), times_flint, color='green', marker='^', label='Flint')\n",
    "plt.plot(range(len(tree_depths)), times_quantize, color='blue', marker='s', label='Quantize')\n",
    "\n",
    "# Set the x-tick labels to the values in tree_depths\n",
    "plt.xticks(range(len(tree_depths)), tree_depths)\n",
    "\n",
    "plt.xlabel('Maximum tree depth')\n",
    "plt.ylabel('Time [s]')\n",
    "plt.title('Average inference time per tree depth')\n",
    "\n",
    "plt.text(0, -0.15, 'Datasets used: '+str(dataset_names)+'.\\nValidation instances per set: '+str(nr_instances_validation)+'\\nValidation set reuses: '+str(nr_validation_reuses)+'\\nSystem info: '+str(architecture), ha='left', va='top', transform=plt.gca().transAxes)\n",
    "\n",
    "# Display the legend\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7",
   "metadata": {},
   "outputs": [],
   "source": [
    "times_per_nr_features= []\n",
    "\n",
    "indices = sorted(range(len(nr_features)), key=nr_features.__getitem__)\n",
    "sorted_nr_features = sorted(nr_features)\n",
    "\n",
    "dataset_names = [func.__name__.replace('datasets.', '') for func in toy_datasets]\n",
    "for i in range(len(dataset_names)):\n",
    "    dataset_names[i] = dataset_names[i].replace('load_', '')\n",
    "\n",
    "times_no_parameters = [[np.mean(times[i*len(tree_depths)*3:i*len(tree_depths)*3+len(tree_depths)*3:3]) for i in range(len(tree_depths))][j] for j in indices]\n",
    "times_flint = [[np.mean(times[i*len(tree_depths)*3+1:i*len(tree_depths)*3+len(tree_depths)*3+1:3]) for i in range(len(tree_depths))][j] for j in indices]\n",
    "times_quantize = [[np.mean(times[i*len(tree_depths)*3+2:i*len(tree_depths)*3+len(tree_depths)*3+2:3]) for i in range(len(tree_depths))][j] for j in indices]\n",
    "\n",
    "\n",
    "\n",
    "# Create the line plot for each group with different colors\n",
    "plt.plot(range(len(sorted_nr_features)), times_no_parameters, color='red', marker='*', label='No parameters')\n",
    "plt.plot(range(len(sorted_nr_features)), times_flint, color='green', marker='^', label='Flint')\n",
    "plt.plot(range(len(sorted_nr_features)), times_quantize, color='blue', marker='s', label='Quantize')\n",
    "\n",
    "# Set the x-tick labels to the values in tree_depths\n",
    "plt.xticks(range(len(sorted_nr_features)), sorted_nr_features)\n",
    "\n",
    "plt.xlabel('Number of features')\n",
    "plt.ylabel('Time [s]')\n",
    "plt.title('Average inference time per number of features')\n",
    "\n",
    "plt.text(0, -0.15, 'Datasets used: '+str(dataset_names)+'.\\nValidation instances per set: '+str(nr_instances_validation)+'\\nValidation set reuses: '+str(nr_validation_reuses)+'\\nSystem info: '+str(architecture), ha='left', va='top', transform=plt.gca().transAxes)\n",
    "\n",
    "# Display the legend\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
